{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento CIS - 4º Período (Redes Neurais)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook implementa uma rede neural do zero para detectar fraudes em transações de cartão de crédito. Utilizamos técnicas de balanceamento de dados e normalização para melhorar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = 'creditcard.csv'\n",
    "credit_card = pd.read_csv(file_path, sep=',', on_bad_lines='skip', low_memory=False)\n",
    "print(credit_card.info())\n",
    "print(credit_card.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir modelos da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da camada da rede neural\n",
    "class NeuralLayer:\n",
    "    def __init__(self, input_size, neuron_count):\n",
    "        self.weights = np.random.randn(input_size, neuron_count) * 0.01\n",
    "        self.biases = np.zeros((1, neuron_count))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.input = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, gradient, learning_rate):\n",
    "        self.dweights = np.dot(self.input.T, gradient) / self.input.shape[0]\n",
    "        self.dbiases = np.sum(gradient, axis=0, keepdims=True) / self.input.shape[0]\n",
    "        self.weights -= learning_rate * self.dweights\n",
    "        self.biases -= learning_rate * self.dbiases\n",
    "        self.dinput = np.dot(gradient, self.weights.T)\n",
    "\n",
    "# Funções de ativação\n",
    "class ReLUActivation:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    def backward(self, gradient):\n",
    "        self.dinput = gradient.copy()\n",
    "        self.dinput[self.output <= 0] = 0\n",
    "\n",
    "class SigmoidActivation:\n",
    "    def forward(self, inputs):\n",
    "        self.output = expit(inputs)\n",
    "        \n",
    "    def backward(self, gradient):\n",
    "        self.dinput = gradient * (self.output * (1 - self.output))\n",
    "\n",
    "# Função de perda\n",
    "class BinaryCrossEntropyLoss:\n",
    "    def calculate(self, predictions, targets):\n",
    "        predictions = np.clip(predictions, 1e-7, 1 - 1e-7)\n",
    "        return -np.mean(targets * np.log(predictions) + (1 - targets) * np.log(1 - predictions))\n",
    "\n",
    "    def backward(self, predictions, targets):\n",
    "        predictions = np.clip(predictions, 1e-7, 1 - 1e-7)\n",
    "        return (predictions - targets) / (predictions * (1 - predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar e Preparar os Dados\n",
    "Nesta seção, carregamos o dataset e separamos as features das labels. Também normalizamos as features para garantir que todas tenham a mesma escala.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e preparar os dados\n",
    "def load_and_prepare_data(file_path):\n",
    "    data_frame = pd.read_csv(file_path)\n",
    "    features = data_frame.drop('Class', axis=1)\n",
    "    labels = data_frame['Class']\n",
    "    return features, labels\n",
    "\n",
    "# Normalizar as variáveis independentes\n",
    "def normalize_features(features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "# Aplicar o SMOTE para balancear as classes\n",
    "def balance_classes(features, labels, strategy=0.3):\n",
    "    smote = SMOTE(sampling_strategy=strategy, random_state=42)\n",
    "    return smote.fit_resample(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição e Treinamento do Modelo\n",
    "Aqui definimos a estrutura da rede neural e implementamos o processo de treinamento. A rede possui três camadas: duas camadas ocultas com ReLU e uma camada de saída com Sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função de treinamento e avaliação\n",
    "def train_and_evaluate_model(X_train, y_train, X_val, y_val, learning_rate, epochs, batch_size):\n",
    "    layer1 = NeuralLayer(X_train.shape[1], 124)\n",
    "    activation1 = ReLUActivation()\n",
    "    layer2 = NeuralLayer(124, 2)\n",
    "    activation2 = ReLUActivation()\n",
    "    layer3 = NeuralLayer(2, 1)\n",
    "    activation3 = SigmoidActivation()\n",
    "    loss_function = BinaryCrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for start in range(0, X_train.shape[0], batch_size):\n",
    "            batch_X = X_train[start:start + batch_size]\n",
    "            batch_y = y_train.iloc[start:start + batch_size].values.reshape(-1, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            layer1.forward(batch_X)\n",
    "            activation1.forward(layer1.output)\n",
    "            layer2.forward(activation1.output)\n",
    "            activation2.forward(layer2.output)\n",
    "            layer3.forward(activation2.output)\n",
    "            activation3.forward(layer3.output)\n",
    "\n",
    "            # Backward pass\n",
    "            gradient = loss_function.backward(activation3.output, batch_y)\n",
    "            activation3.backward(gradient)\n",
    "            layer3.backward(activation3.dinput, learning_rate)\n",
    "            activation2.backward(layer3.dinput)\n",
    "            layer2.backward(activation2.dinput, learning_rate)\n",
    "            activation1.backward(layer2.dinput)\n",
    "            layer1.backward(activation1.dinput, learning_rate)\n",
    "\n",
    "        # Avaliação no conjunto de validação\n",
    "        layer1.forward(X_val)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        layer3.forward(activation2.output)\n",
    "        activation3.forward(layer3.output)\n",
    "\n",
    "        val_loss = loss_function.calculate(activation3.output, y_val.values.reshape(-1, 1))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {val_loss:.4f}\")\n",
    "\n",
    "    return layer1, activation1, layer2, activation2, layer3, activation3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de hiperparâmetros\n",
    "def main(learning_rates,epochs,batch_size,best_model,best_f1_score):\n",
    "    features, labels = load_and_prepare_data('creditcard.csv')\n",
    "    normalized_features = normalize_features(features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(normalized_features, labels, test_size=0.5, random_state=42)\n",
    "    X_resampled, y_resampled = balance_classes(normalized_features, labels)\n",
    "\n",
    "    X_train_resampled, X_val_resampled, y_train_resampled, y_val_resampled = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        print(f\"\\nTreinando com taxa de aprendizado = {learning_rate}\")\n",
    "        model = train_and_evaluate_model(X_train_resampled, y_train_resampled, X_val_resampled, y_val_resampled, learning_rate, epochs, batch_size)\n",
    "\n",
    "        layer1, activation1, layer2, activation2, layer3, activation3 = model\n",
    "\n",
    "        # Avaliação no conjunto de validação\n",
    "        layer1.forward(X_val_resampled)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        layer3.forward(activation2.output)\n",
    "        activation3.forward(layer3.output)\n",
    "\n",
    "        y_pred_val = (activation3.output >= 0.5).astype(int)\n",
    "        accuracy_val = accuracy_score(y_val_resampled, y_pred_val)\n",
    "        precision_val = precision_score(y_val_resampled, y_pred_val)\n",
    "        recall_val = recall_score(y_val_resampled, y_pred_val)\n",
    "        f1_val = f1_score(y_val_resampled, y_pred_val)\n",
    "\n",
    "        print(f\"Validação: Acurácia = {accuracy_val:.4f}\")\n",
    "        print(f\"Validação: Precisão = {precision_val:.4f}\")\n",
    "        print(f\"Validação: Recall = {recall_val:.4f}\")\n",
    "        print(f\"Validação: F1 = {f1_val:.4f}\")\n",
    "\n",
    "\n",
    "        # Selecionar o melhor modelo\n",
    "        if f1_val > best_f1_score:\n",
    "            best_f1_score = f1_val\n",
    "            best_model = model\n",
    "\n",
    "    # Previsão no conjunto de teste\n",
    "    layer1, activation1, layer2, activation2, layer3, activation3 = best_model\n",
    "\n",
    "    layer1.forward(X_test)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    layer3.forward(activation2.output)\n",
    "    activation3.forward(layer3.output)\n",
    "\n",
    "    y_pred_test = (activation3.output >= 0.5).astype(int)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # Resultados finais\n",
    "    print(\"\\nResultados finais:\")\n",
    "    print(f\"Acurácia = {accuracy_test:.4f}\")\n",
    "    print(f\"Precisão = {precision_test:.4f}\")\n",
    "    print(f\"Recall = {recall_test:.4f}\")\n",
    "    print(f\"F1 = {f1_test:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir parâmetros de treinamento e treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando com taxa de aprendizado = 0.001\n",
      "Epoch 0: Loss = 0.5394\n",
      "Epoch 100: Loss = 0.0078\n",
      "Epoch 200: Loss = 0.0038\n",
      "Validação: Acurácia = 0.9994\n",
      "Validação: Precisão = 0.9976\n",
      "Validação: Recall = 1.0000\n",
      "Validação: F1 = 0.9988\n",
      "\n",
      "Treinando com taxa de aprendizado = 0.005\n",
      "Epoch 0: Loss = 0.4325\n",
      "Epoch 100: Loss = 0.0030\n",
      "Epoch 200: Loss = 0.0028\n",
      "Validação: Acurácia = 0.9996\n",
      "Validação: Precisão = 0.9981\n",
      "Validação: Recall = 1.0000\n",
      "Validação: F1 = 0.9991\n",
      "\n",
      "Treinando com taxa de aprendizado = 0.01\n",
      "Epoch 0: Loss = 0.1039\n",
      "Epoch 100: Loss = 0.0034\n",
      "Epoch 200: Loss = 0.0033\n",
      "Validação: Acurácia = 0.9996\n",
      "Validação: Precisão = 0.9984\n",
      "Validação: Recall = 1.0000\n",
      "Validação: F1 = 0.9992\n",
      "\n",
      "Treinando com taxa de aprendizado = 0.05\n",
      "Epoch 0: Loss = 0.0238\n",
      "Epoch 100: Loss = 0.0018\n",
      "Epoch 200: Loss = 0.0023\n",
      "Validação: Acurácia = 0.9995\n",
      "Validação: Precisão = 0.9977\n",
      "Validação: Recall = 1.0000\n",
      "Validação: F1 = 0.9988\n",
      "\n",
      "Treinando com taxa de aprendizado = 0.1\n",
      "Epoch 0: Loss = 0.0129\n",
      "Epoch 100: Loss = 0.0034\n",
      "Epoch 200: Loss = 0.0030\n",
      "Validação: Acurácia = 0.9995\n",
      "Validação: Precisão = 0.9979\n",
      "Validação: Recall = 1.0000\n",
      "Validação: F1 = 0.9989\n",
      "\n",
      "Treinando com taxa de aprendizado = 0.15\n",
      "Epoch 0: Loss = 0.0193\n",
      "Epoch 100: Loss = 12.3901\n",
      "Epoch 200: Loss = 12.3901\n",
      "Validação: Acurácia = 0.2313\n",
      "Validação: Precisão = 0.2313\n",
      "Validação: Recall = 1.0000\n",
      "Validação: F1 = 0.3757\n",
      "\n",
      "Treinando com taxa de aprendizado = 0.2\n",
      "Epoch 0: Loss = 0.0228\n",
      "Epoch 100: Loss = 3.7280\n",
      "Epoch 200: Loss = 3.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caefleury/Documents/unb/trainee-cis-ieee/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação: Acurácia = 0.7687\n",
      "Validação: Precisão = 0.0000\n",
      "Validação: Recall = 0.0000\n",
      "Validação: F1 = 0.0000\n",
      "\n",
      "Resultados finais:\n",
      "Acurácia = 0.9997\n",
      "Precisão = 0.8601\n",
      "Recall = 1.0000\n",
      "F1 = 0.9248\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "best_model = None\n",
    "best_f1_score = 0\n",
    "\n",
    "main(learning_rates,epochs,batch_size,best_model,best_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O código implementa uma rede neural do zero para detecção de fraudes em transações de cartão de crédito.\n",
    "\n",
    "### Pré-processamento dos Dados:\n",
    "\n",
    "Carregamento do dataset e separação das features e labels.\n",
    "Normalização das features para garantir que todas tenham a mesma escala.\n",
    "Uso do SMOTE para balancear as classes, aumentando a quantidade de exemplos da classe minoritária.\n",
    "\n",
    "### Estrutura da Rede Neural:\n",
    "\n",
    "A rede possui três camadas: duas camadas ocultas com a função de ativação ReLU e uma camada de saída com a função de ativação Sigmoid.\n",
    "A função de perda utilizada é a Binary Cross-Entropy.\n",
    "\n",
    "### Treinamento e Avaliação:\n",
    "\n",
    "O modelo é treinado com diferentes taxas de aprendizado, variando de 0.001 a 0.2.\n",
    "Durante o treinamento, a perda é monitorada a cada 100 épocas.\n",
    "\n",
    "O desempenho do modelo é avaliado usando métricas como acurácia, precisão, recall e F1-score no conjunto de validação.\n",
    "\n",
    "\n",
    "## Análise dos Resultados\n",
    "\n",
    "### Taxas de Aprendizado Baixas a Moderadas (0.001 a 0.1):\n",
    "\n",
    "As taxas de aprendizado de 0.001 a 0.1 resultaram em um bom desempenho, com acurácia e F1-score próximos de 1.0.\n",
    "\n",
    "A perda diminuiu significativamente ao longo das épocas, indicando que o modelo estava aprendendo bem.\n",
    "\n",
    "A precisão, recall e F1-score foram todos muito altos, sugerindo que o modelo estava equilibrado em termos de predição de classes positivas e negativas.\n",
    "\n",
    "### Taxas de Aprendizado Altas (0.15 e 0.2):\n",
    "\n",
    "As taxas de aprendizado de 0.15 e 0.2 resultaram em um desempenho significativamente pior.\n",
    "\n",
    "A perda aumentou drasticamente, indicando que o modelo estava instável e não convergindo adequadamente.\n",
    "\n",
    "A precisão e o F1-score caíram drasticamente, especialmente para a taxa de aprendizado de 0.2, onde a precisão foi definida como 0 devido à falta de amostras previstas corretamente.\n",
    "\n",
    "### Resultados Finais:\n",
    "\n",
    "O melhor desempenho foi observado com taxas de aprendizado entre 0.005 e 0.01, onde o modelo alcançou uma acurácia de 0.9997 e um F1-score de 0.9248 no conjunto de teste.\n",
    "\n",
    "Isso sugere que essas taxas de aprendizado proporcionaram um bom equilíbrio entre velocidade de convergência e estabilidade do modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
